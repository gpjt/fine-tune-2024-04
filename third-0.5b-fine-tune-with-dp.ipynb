{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a69fbb-73f6-44b4-9ba8-69af4d8cd728",
   "metadata": {},
   "source": [
    "# Third fine-tuning with a 0.5B parameter model, using `DataParallel`\n",
    "\n",
    "My goal is to fine-tune meta-llama/Meta-Llama-3-8B on timdettmers/openassistant-guanaco.  This notebook reworks `second-0.5b-fine-tune.ipynb` so that it can use the `DataParallel` wrapper to tune over multiple GPUs.  It also strips out a lot of the investigatory stuff from that notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7737e-fc33-4770-9fe2-6ddfd17f18ff",
   "metadata": {},
   "source": [
    "## The dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e953815f-0679-4b63-9945-4a26f8945d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_source = \"timdettmers/openassistant-guanaco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d591f1d7-1c2a-4270-a40a-a60a62b9756a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661335e5-6a77-4908-af55-43d6d18f9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "{question} [/INST]\n",
    "{response}\n",
    "\"\"\"\n",
    "\n",
    "pattern = r\"### Human: (.*?)### Assistant: (.*)\"\n",
    "\n",
    "def rewrite_prompts(examples):\n",
    "    questions = []\n",
    "    responses = []\n",
    "    # Iterate over each example\n",
    "    for text in examples[\"text\"]:\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            question = match.group(1).strip()\n",
    "            response = match.group(2).strip()\n",
    "            reformatted_text = prompt_template.format(question=question, response=response)\n",
    "            while \"### Human: \" in reformatted_text:\n",
    "                reformatted_text = reformatted_text.replace(\"### Human: \", \"[INST]\", 1)\n",
    "                if \"### Assistant: \" in reformatted_text:\n",
    "                    reformatted_text = reformatted_text.replace(\"### Assistant: \", \"[/INST]\\n\", 1)\n",
    "                else:\n",
    "                    reformatted_text += \"[/INST]\\n\"\n",
    "                    \n",
    "            responses.append(reformatted_text)\n",
    "        else:\n",
    "            # You might want to handle errors differently\n",
    "            responses.append(\"Error: Did not match expected pattern.\")\n",
    "    return {\"reformatted_text\": responses}\n",
    "\n",
    "# Apply the function to your dataset\n",
    "reformatted_dataset = dataset.map(rewrite_prompts, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21d742-f5a1-4502-9e24-63aa499fece0",
   "metadata": {},
   "source": [
    "## The model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63348a8b-6dda-49b0-ba8e-68534a373093",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"Qwen/Qwen1.5-0.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b083c798-c528-437f-802b-aba380590a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55f1836-87da-4f2f-b382-80be61d8ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import DataParallel\n",
    "\n",
    "parallel_model = DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3867283-e1a0-4e30-826f-b9fb0219b850",
   "metadata": {},
   "source": [
    "## Initial inference check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f8173-ac3f-4c28-a40c-e77ac17d9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset = reformatted_dataset['train'].map(lambda row: tokenizer(row[\"reformatted_text\"]))\n",
    "tokenized_test_dataset = reformatted_dataset['test'].map(lambda row: tokenizer(row[\"reformatted_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f0fcf-11a5-458b-81aa-e601acab1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "\n",
    "batch_size = 1\n",
    "args = TrainingArguments(\n",
    "    'outputs', \n",
    "    learning_rate=8e-5, \n",
    "    warmup_ratio=0.1, \n",
    "    lr_scheduler_type='cosine', \n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size * 2,\n",
    "    num_train_epochs=2, \n",
    "    weight_decay=0.01, \n",
    "    report_to='none',\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344da802-4c57-4de0-ab3c-0ce5b2f8cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(examples[\"reformatted_text\"], truncation=True, padding=\"max_length\", max_length=2048)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"][:]\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = reformatted_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47356b2f-ae28-49ad-8880-b01a2350814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    parallel_model, args, \n",
    "    train_dataset=tokenized_dataset['train'], \n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a2114-9970-4db7-ad90-94fb0b9e47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc103cfb-0641-479a-8b2c-7c5e8870ab2f",
   "metadata": {},
   "source": [
    "Turns out that it still starts getting worse validation loss after the second epoch -- so the instruction formatting didn't help with that.  But let's see what we get as a result when we try it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5545fbb-f801-4a8b-be62-d01564e40de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question(trainer.model, \"Who is Leonardo Da Vinci?\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72058af0-5d39-47c4-878b-cde9735cea89",
   "metadata": {},
   "source": [
    "To me, that looks better vibe-wise than the previous fine-tune.  Plenty of hallucinations, but not bad at all!  However, it's added a Human/Assistant thing at the end (previous runs didn't show that).  We should fix that by fixing our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310db09-e8d7-4651-8c22-f0c6d8c91c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
